{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <center> Udacity Machine Learning Capstone Project: MLB Wins Prediction </center>\n",
    " ## <center>John K. Hancock, August 2018</center>\n",
    " ### <center>username: jkhancock@gmail.com</center>\n",
    " \n",
    "\n",
    "\n",
    "<center> <img src=\"mlb_logo.jpg\" align=\"center\" alt=\"Copyright Major League Baseball\" height=\"320\" width=\"320\" /></center> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>MLB Wins Prediction</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Problem-Statement'><font color=black><u>Problem Statement</u></font></a>\n",
    "A new general manager (\"GM\") of a major league baseball team has been hired with the task of getting the team into the playoffs. The GM knows that to make the playoffs the team needs to have more wins than most other teams. In order to solve this problem, the GM wants to know what key performance statistics that his teams need to achieve in order to maximize the number of wins.\n",
    "\n",
    "The GM has tasked his Lead Data Scientist (\"LDS\") to build a model that can predict how many wins a team will have based on historical\n",
    "statistical data from winning teams and list the key statistical features that winning team can have. In\n",
    "the end, the GM will use this model to find players that fit these key statistical features. For example, if\n",
    "On-Base Percentage (“OBP”) shows that leads to more wins, the GM will look for players that have\n",
    "demonstrated high OBP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='Datasets-Inputs'><font color=black><u>Datasets and Inputs</u></font></a>\n",
    "Baseball has a long history of meticulous record keeping which laid the groundwork for data\n",
    "exploration and analysis, and there are several well established sources of data for this project. Perhaps the most comprehensive source is the website, FanGraphs.com (www.fangraphs.com). \n",
    "\n",
    "Fangraphs.com is website operated by FanGraphs, Inc. Fangraphs compiles historical statistical data for the entire history of Major League Baseball.  In addition, it creates and records advanced baseball metrics outside of the established statistics. FanGraphs is well established as a chronicler and compiler of baseball statistics.  It has parternership deals with ESPN and SB Nation. (Link to website: https://www.fangraphs.com/) (Wikipedia: https://en.wikipedia.org/wiki/Fangraphs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Solution-Statement'><font color=black><u>Solution Statement</u></font></a>\n",
    "To predict wins, the Data Scientist will need to build a mapping function using historical team statistics for the past 20 years as input variables to predict the output variable (the number of wins). For this step, s/he will use the standard Linear Regression classification algorithm from Sci-kit Learn. Additionally, the Data Scientist will also use Deep Learning Neural Networks to perform Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Project-Design'><font color=black><u>Project Design</u></font></a>\n",
    "\n",
    "#### <u> Part One: Data Collection and Data Wrangling </u>\n",
    "\n",
    "In part one, of this project, twenty years of all available MLB statistics were collected from the website, fangraphs.com.  The data was then explored, cleaned, and wrangled into a final datatset, \"FINAL_DATASET_MLB_1998_to_2017.csv\". Please see the notebook, <i><b>00_Capstone_Project_MLB_Collection_Wrangling</i></b>, located in the folder, 00_Data Collection and Wrangling for more details and explanations. \n",
    "\n",
    "#### <a id=\"home\"><font color=black><u> Part Two: The Model </u></font></a>\n",
    "[0.0 The Final Dataset: Descriptive Statistics](#0.0)<br />\n",
    "[1.0 A Look at MLB Wins](#1.0)<br />\n",
    "[2.0 Separate the dependent variable from the independent variables](#2.0)<br />\n",
    "[3.0 Outliers](#3.0)<br />\n",
    "&nbsp; &nbsp; [3.1 Remove Outliers ](#3.1)<br />\n",
    "[4.0 Check for Skewness](#4.0)<br />\n",
    "[5.0 Pre-Processing data](#5.0)<br />\n",
    " &nbsp; &nbsp; [5.1 Select The Best Features](#5.1)<br />\n",
    "  &nbsp; &nbsp; [5.2 Split the Dataset](#5.2)<br />\n",
    "[6.0 Model One: LASSO Regression](#6.0)<br />\n",
    "[7.0 Model Two: Linear Regression with Deep Neural Network](#7.0)<br />\n",
    "[8.0 Cluster Segment Analysis](#8.0)<br />\n",
    "[9.0 Final Summary ](#9.0)<br />\n",
    "[10.0 Project Reflections ](#10.0)<br />\n",
    "[11.0 References](#11.0)<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='0.0'><font color=black><u>0.0 The Final Dataset: Descriptive Statistics</u></font></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "import visuals as vs\n",
    "import capstoneutils as hp\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "path = os.getcwd()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\Users\\\\jkhan\\\\Documents\\\\udacity\\\\MLND\\\\Capstone Project\\\\CAPSTONE FINAL PROJECT\\\\01_The Model\\\\FINAL DATASET version 1.0\\\\FINAL DATASET version 1.0\\\\FINAL_DATASET_MLB_1998_to_2017.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-8e87af01414b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mFinal_MLB_Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mFinal_MLB_Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34mr'\\FINAL DATASET version 1.0\\FINAL_DATASET_MLB_1998_to_2017.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"The baseball dataset has {} data points with {} variables each.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mFinal_MLB_Data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\Users\\\\jkhan\\\\Documents\\\\udacity\\\\MLND\\\\Capstone Project\\\\CAPSTONE FINAL PROJECT\\\\01_The Model\\\\FINAL DATASET version 1.0\\\\FINAL DATASET version 1.0\\\\FINAL_DATASET_MLB_1998_to_2017.csv' does not exist"
     ]
    }
   ],
   "source": [
    "Final_MLB_Data = pd.DataFrame()\n",
    "Final_MLB_Data = pd.read_csv(path +r'\\FINAL DATASET version 1.0\\FINAL_DATASET_MLB_1998_to_2017.csv', index_col=0)\n",
    "print (\"The baseball dataset has {} data points with {} variables each.\".format(*Final_MLB_Data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary fielding statistics are below:\")\n",
    "Final_MLB_Data[['FIELD_E', 'FIELD_DP', 'FIELD_SB', 'FIELD_CS', 'FIELD_PB',\n",
    "       'FIELD_WP', 'FIELD_FP', 'FIELD_PO']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary hitting statistics are below:\")\n",
    "Final_MLB_Data[['OFF_PA', 'OFF_HR', 'OFF_R',\n",
    "       'OFF_RBI', 'OFF_SB', 'OFF_ISO', 'OFF_BABIP', 'OFF_AVG', 'OFF_OBP',\n",
    "       'OFF_SLG', 'OFF_wOBA', 'OFF_wRC+', 'OFF_H', 'OFF_1B', 'OFF_2B',\n",
    "       'OFF_3B', 'OFF_BB', 'OFF_IBB', 'OFF_SO', 'OFF_HBP', 'OFF_SF',\n",
    "       'OFF_GDP', 'OFF_CS', 'OFF_BB%', 'OFF_K%', 'OFF_BB/K']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary pitching statistics are below:\")\n",
    "Final_MLB_Data[['PITCH_ERA', 'PITCH_CG', 'PITCH_ShO', 'PITCH_SV', 'PITCH_H',\n",
    "       'PITCH_R', 'PITCH_ER', 'PITCH_HR', 'PITCH_BB', 'PITCH_IBB',\n",
    "       'PITCH_HBP', 'PITCH_WP', 'PITCH_BK', 'PITCH_SO', 'PITCH_K/9',\n",
    "       'PITCH_BB/9', 'PITCH_K/BB', 'PITCH_H/9', 'PITCH_HR/9', 'PITCH_AVG',\n",
    "       'PITCH_WHIP', 'PITCH_BABIP', 'PITCH_LOB%', 'PITCH_FIP',\n",
    "       'PITCH_Starting', 'PITCH_Relieving', 'PITCH_Start-IP',\n",
    "       'PITCH_Relief-IP', 'PITCH_K%', 'PITCH_BB%', 'PITCH_Age']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black><u><b>The Pythagorean Theorem of Baseball</b></u></font><br />\n",
    "The Pythagorean Theorem of Baseball is a creation of Bill James which relates the number of runs a team has scored and surrendered to its actual winning percentage, based on the idea that runs scored compared to runs allowed is a better indicator of a team's (future) performance than a team's actual winning percentage. This results in a formula which is referred to as Pythagorean Winning Percentage. (Baseball Reference.com https://www.baseball-reference.com/bullpen/Pythagorean_Theorem_of_Baseball)<br />\n",
    "\n",
    "The formula is \"1 / (1 + (Runs Allowed / Runs Scored)^2)\". The results below show that even with this traditional wins prediction heuristic there is variance between what the formula predicts and the actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Baseball's Pythagorean Thereom 1 / (1 + (Runs Allowed / Runs Scored)**2)\n",
    "\n",
    "min_runs_allowed = Final_MLB_Data['PITCH_R'].min()\n",
    "runs_scored = Final_MLB_Data.loc[Final_MLB_Data['PITCH_R'] == min_runs_allowed]['OFF_R'].item()\n",
    "win_total = Final_MLB_Data.loc[Final_MLB_Data['PITCH_R'] == min_runs_allowed]['W'].item()\n",
    "pythag1 =  float(1 / (1 + (min_runs_allowed/runs_scored)**2))\n",
    "expected_wins1 = 162*pythag1\n",
    "\n",
    "max_runs_scored = Final_MLB_Data['OFF_R'].max()\n",
    "runs_allowed = Final_MLB_Data.loc[Final_MLB_Data['OFF_R'] == max_runs_scored]['PITCH_R'].item()\n",
    "win_total2 = Final_MLB_Data.loc[Final_MLB_Data['OFF_R'] == max_runs_scored]['W'].item()\n",
    "pythag2 = float(1 / (1 + (runs_allowed/max_runs_scored)**2))\n",
    "expected_wins2 = 162*pythag2\n",
    "\n",
    "    \n",
    "    \n",
    "print(\"The minimum number of runs allowed by a team over the past 20 years is %.0f and that team's win total was %.0f.\" % (min_runs_allowed, win_total))\n",
    "print(\"That same team scored %.0f runs for a run differential of %.0f\" % (runs_scored, runs_scored-min_runs_allowed))\n",
    "print(\"According to the Pythagorean Theorem of Baseball, the team's win total should have been %.2f\" % expected_wins1)\n",
    "print(\"\\n\")\n",
    "print(\"The maximum number of runs scored by a team over the past 20 years is %.0f and that team's win total was %.0f.\" % (max_runs_scored, win_total2))\n",
    "print(\"That same team allowed %.0f runs for a run differential of %.0f\" % (runs_allowed, max_runs_scored-runs_allowed))\n",
    "print(\"According to the Pythagorean Theorem of Baseball, the team's win total should have been %.2f\" % expected_wins2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='1.0'><font color=black><u>1.0 A Look at MLB Wins </u></font></a>  \n",
    "\n",
    "The objective of this project is to build a model that can predict the number of wins and lists the most important features that are important to winning. Over the past 20 year, the average and median number of wins is 81 games, and the standard deviation is 11.52. In order to make the playoffs, the team needs to win at least one full standard deviation above the mean or 93 wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Median No. of Wins is %.0f\" % Final_MLB_Data['W'].median()\n",
    "\n",
    "Final_MLB_Data['W'].plot.hist(grid=True, bins=40, rwidth=0.9,color='green')\n",
    "plt.title('MLB Team Wins')\n",
    "plt.xlabel('Wins')\n",
    "plt.ylabel('Number of seasons')\n",
    "plt.text(41,40,text)\n",
    "plt.grid(axis='y', alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average number of wins %.0f.\" % Final_MLB_Data['W'].mean())\n",
    "print(\"The median number of wins %.2f.\" % Final_MLB_Data['W'].median())\n",
    "print(\"The standard deviation for wins is %.2f.\" % Final_MLB_Data['W'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Total number is %d or %.2f%%\" % (Final_MLB_Data.loc[Final_MLB_Data['W'] >= 93, ['W']].count(), float((Final_MLB_Data.loc[Final_MLB_Data['W'] >= 93, ['W']].count())/(Final_MLB_Data['W'].count()))*100)\n",
    "\n",
    "Final_MLB_Data.loc[Final_MLB_Data['W'] >= 93, ['W']].plot.hist(grid=True, bins=40, rwidth=0.9,color='blue')\n",
    "plt.title('Seasons an MLB Team Won 93 or more Games')\n",
    "plt.xlabel('Wins')\n",
    "plt.ylabel('Number of seasons')\n",
    "plt.text(98,17.5,text)\n",
    "plt.grid(axis='y', alpha=0.55)\n",
    "plt.grid(axis='x', alpha=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Total number is %d or %.2f%%\" % (Final_MLB_Data.loc[Final_MLB_Data['W'] >= 95, ['W']].count(), float((Final_MLB_Data.loc[Final_MLB_Data['W'] >= 95, ['W']].count())/(Final_MLB_Data['W'].count()))*100)\n",
    "\n",
    "Final_MLB_Data.loc[Final_MLB_Data['W'] >= 95, ['W']].plot.hist(grid=True, bins=40, rwidth=0.9,color='orange')\n",
    "plt.title('Seasons MLB Team Won 95 or more Games')\n",
    "plt.xlabel('Wins')\n",
    "plt.ylabel('Number of seasons')\n",
    "plt.text(98,17.5,text)\n",
    "plt.grid(axis='y', alpha=0.55)\n",
    "plt.grid(axis='x', alpha=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Total number is %d or %.2f%%\" % (Final_MLB_Data.loc[Final_MLB_Data['W'] >= 100, ['W']].count(), float((Final_MLB_Data.loc[Final_MLB_Data['W'] >= 100, ['W']].count())/(Final_MLB_Data['W'].count()))*100)\n",
    "\n",
    "Final_MLB_Data.loc[Final_MLB_Data['W'] >= 100, ['W']].plot.hist(grid=True, bins=40, rwidth=0.9,color='red')\n",
    "plt.title('Seasons MLB Team Won 100 or more Games')\n",
    "plt.xlabel('Wins')\n",
    "plt.ylabel('Number of seasons')\n",
    "plt.text(104,3.5,text)\n",
    "plt.grid(axis='y', alpha=0.55)\n",
    "plt.grid(axis='x', alpha=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_93 = (Final_MLB_Data.loc[Final_MLB_Data['W'] >= 93, ['W']].count())/(Final_MLB_Data['W'].count())*100\n",
    "prob_95 = (Final_MLB_Data.loc[Final_MLB_Data['W'] >= 95, ['W']].count())/(Final_MLB_Data['W'].count())*100\n",
    "prob_100 = (Final_MLB_Data.loc[Final_MLB_Data['W'] >= 100, ['W']].count())/(Final_MLB_Data['W'].count())*100\n",
    "print(\"To summarize:\")\n",
    "print(\"The probabilty of winning 93 or more games is %.2f%%.\" % prob_93 )\n",
    "print(\"The probabilty of winning 95 or more games is %.2f%%.\" % prob_95 )\n",
    "print(\"The probabilty of winning 100 or more games is %.2f%%.\" % prob_100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='1.0'><font color=black><u>1.1 Dataset information </u></font></a>\n",
    "\n",
    "By looking at the shape, describing the data, and the information for the data, we see that all of the variables are continuous data, not categorical.  For the purpose of this project, we won't need to convert any column, e.g. one-hot-encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_MLB_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='2.0'><font color=black><u>2.0 Separate the indepenedent and dependent variables </u></font></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the predictor variables by first dropping the \"L\" column\n",
    "Final_MLB_Data= Final_MLB_Data.drop(\"L\", axis=1)\n",
    "#Create the target variable Wins\n",
    "Wins = Final_MLB_Data[\"W\"]\n",
    "#Remove the target from the features\n",
    "features = Final_MLB_Data.drop(\"W\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='3.0'><font color=black><u>3.0 Remove Outliers </u></font></a>\n",
    "\n",
    "In this section, outliers in the dataset are identified and removed.  \"Tukey's Method for identfying outliers: An outlier step is calculated as 1.5 times the interquartile range (IQR). A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal.\" (citation: Udacity MLND course on Unsupervised Learning. Customer Segments project.)(Turkey's Method: http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/)\n",
    "\n",
    "(See the function: detect_outliers in capstoneutils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = hp.detect_outliers(features)\n",
    "outliers  = [list(cnt.keys())] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <a id='3.1'><font color=black><u>3.1 Remove Outliers </u></font></a>\n",
    "\n",
    "From the dictionary, we can see that six observations at indexes 59, 30, 570, 573, and 598 have a high number of outlier features (more than 4).  These observations are removed from both the features and Wins datasets.  The number of observations for both datasets is now 594."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop([59,30,570,0,573,598])\n",
    "Wins = Wins.drop([59,30,570,0,573,598])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Wins.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4.0'><font color=black><u>4.0 Check for Skewness </u></font></a>\n",
    "\n",
    "Skewness is a measure of symmetry, or lack thereof, in a dataset while Kurtosis is a measure of how large the tails are compared to a normal distribution.  If both skew and kurtosis are 0, then the data is normally distributed.  In the code below, I culled out those features with a skew and kurtosis greater than .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "skewed_features = {}\n",
    " \n",
    "for col in features.columns:\n",
    "    arry = np.array(features[col])\n",
    "    skew_value = skew(arry)\n",
    "    if skew_value> 1 or skew_value < -1:\n",
    "        skewed_features[col] = [skew_value]\n",
    "    \n",
    "skewed_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=features['OFF_IBB'], bins=50)\n",
    "plt.xlabel('Number of Intentional Walks for a Team')\n",
    "plt.title(\"Pre Transformed Feature Intentional Walks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=features['FIELD_PB'], bins=50)\n",
    "plt.xlabel('Number of Passed Balls(Errors) for a Team')\n",
    "plt.title(\"Pre Transformed Feature Passed Balls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=features['FIELD_PB'], bins=50)\n",
    "plt.xlabel('Number of Passed Balls(Errors) for a Team')\n",
    "plt.title(\"Pre Transformed Feature Complete Games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4.1'><font color=black><u>4.1 Check for Skewness </u></font></a>\n",
    "\n",
    "In this section, I transformed the skewed features of the dataset identified above by taking the log of the feature + 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the skewed features\n",
    "skewed = [keys for keys in skewed_features.keys()]\n",
    "features[skewed] = features[skewed].apply(lambda x: np.log(x+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_skewed_features = {}\n",
    "\n",
    "for col in features[skewed]:\n",
    "    arry = np.array(features[col])\n",
    "    skew_value = skew(arry)\n",
    "    transformed_skewed_features[col] = [skew_value]\n",
    "        \n",
    "transformed_skewed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=features['OFF_IBB'], bins=50)\n",
    "plt.xlabel('Number of Intentional Walks for a Team')\n",
    "plt.title(\"Transformed Feature Intentional Walks for a Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=features['FIELD_PB'], bins=50)\n",
    "plt.xlabel('Number of Passed Balls(Errors) for a Team')\n",
    "plt.title(\"Transformed Feature Intentional Walks for a Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=features['PITCH_CG'], bins=50)\n",
    "plt.xlabel('Number of Complete Games Pitched by a Starter for a Team')\n",
    "plt.title(\"Transformed Feature Complete Games Pitched by a Starter for a Team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='5.0'><font color=black><u>5.0 Pre Process Dataset </u></font></a>\n",
    "\n",
    "In this section, I applied the MinMaxScaler to the log transformed features in order to better normalize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  MinMaxScaler()\n",
    "\n",
    "numerical = features.columns.values.tolist()\n",
    "\n",
    "features[numerical ] = scaler.fit_transform(features[numerical])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "kbest = SelectKBest(f_regression, k='all')\n",
    "kbest.fit_transform(features, Wins)\n",
    "\n",
    "scores = kbest.scores_\n",
    "features_scores = dict(zip(features,scores))\n",
    "feats = list()\n",
    "for k,v in features_scores.items():\n",
    "    if v > 50:\n",
    "        feats.append(k)\n",
    "features = features[feats]\n",
    "features_scores = sorted(features_scores.items(), key=lambda kv: kv[1])\n",
    "print(\"These are the top 40 features, and their scores, that will be fed into the model:\")\n",
    "pp.pprint(features_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='5.2'><font color=black><u>5.2 Split the Dataset </u></font></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, Wins, test_size=.2, random_state=9)\n",
    "print (\"Training and testing split was successful.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### <a id='6.0'><font color=black><u>6.0 Model One: LASSO Regression </u></font></a>\n",
    " \n",
    "Least Absolute Selection and Shrinkage Operator or \"LASSO\" regression model was the first choice for this project given the high number of features in the dataset and the low number of observations. LASSO is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.LASSO imposes a constraint on the sum of the absolute values of the model parameters, where the sum has a specified constant as an upper bound. This constraint causes regression coefficients for some variables to shrink towards zero,  effectively choosing a simpler model that does not include those coefficients. https://en.wikipedia.org/wiki/Lasso_(statistics).\n",
    "\n",
    "In the Lasso regression model imported from sklearn, uses Regularization penalizes model complexity. The lambda parameter penalizes the coefficients so that the model does not over fit. Ridge Regression uses L1 Regularizaton. Ridge regression improves prediction error by shrinking large regression coefficients in order to reduce overfitting, but it does not perform covariate selection and therefore does not help to make the model more interpretable. https://en.wikipedia.org/wiki/Lasso_(statistics)\n",
    "\n",
    "Lasso uses L2 Regularization which forces the sum of the absolute value of the regression coefficients to be less than a fixed value, and in turn forces certain coefficients to be set to zero, effectively choosing a simpler model that does not include those coefficients. https://en.wikipedia.org/wiki/Lasso_(statistics)\n",
    "\n",
    "In sum, due to the high number of features, the model will reduce the coefficients of most of them to zero in order to create a simpler, more accurate prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Lasso(random_state=5)\n",
    "alphas = 10**np.linspace(10, -2, 100)*0.5\n",
    "\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 25\n",
    "\n",
    "clf = GridSearchCV(lasso, tuned_parameters, cv=n_folds)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "scores_std = clf.cv_results_['std_test_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph below, you can visually see how the Lasso model sets the weights of several of the features to zero thereby removing it from the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.pprint(clf.cv_results_['params'])\n",
    "plt.figure(figsize=(10,10))\n",
    "top_coef = pd.Series(clf.best_estimator_.coef_, X_train.columns).sort_values()\n",
    "top_coef.plot(kind='bar', title='Weights of Feature Coefficients')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error measures the average squared difference between the prediction values and the actual values. The MSE is lower on the training set than it is on the test set, which is a sign that the model is not over-fitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, clf.predict(X_train))\n",
    "test_error = mean_squared_error(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "print ('The training data MSE is %.3f' % train_error)\n",
    "print ('The test data MSE is %.3f' % test_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination, or R-squared, is the proportion of the variance in the dependent variable (Wins) that is predictable from the independent variables. In sum, it provides a statistic that evaluates how well the model fits the data.  The statistic ranges from 0 to 1 where \"1\" fits the data perfectly and 0 means that the model explains none of the variability of the response data. For this project, the R-square score when the model is tested against the test data is 0.76 which indicates a high correlation between the number of features and the number of wins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-square from training and test data\n",
    "\n",
    "rsquared_train=clf.score(X_train,y_train)\n",
    "rsquared_test=clf.score(X_test,y_test)\n",
    "print ('The training data R-square is %.2f' % rsquared_train)\n",
    "print ('The testing data R-square is %.2f' % rsquared_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graphic below, the scatter plot compares what the model predicted and what the actual win total was.\n",
    "\n",
    "The yellow color dots show where the model predicted more wins than the actual total.<br />\n",
    "The purple color dots show where the model predicted less wins than the actual total.<br />\n",
    "The green color dots show where the model predicted the same or nearly the same as the actual total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(preds,  y_test, c=preds-y_test)\n",
    "plt.ylim(40,120)\n",
    "\n",
    "\n",
    "plt.xlabel('Model Predictions')\n",
    "plt.ylabel('Actual Wins')\n",
    "plt.title('Model One Predictions vs. Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    diff = y_test.iloc[i] - preds[i]\n",
    "    print(\"The model predicts %d and the actual number is %d. The difference is %d\" % (preds[i],y_test.iloc[i], diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model One Summary</b><br/>\n",
    "\n",
    "This model shows that the features that carry the most weight--where weights are greater than or equal to 2-- in terms of predicting wins are listed below. Pitching stats carry more weight than hitting or fielding.  According to this model, the team should prioritize pitchers who excel in these 21 features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actual_df = pd.DataFrame( index=range(0,119))\n",
    "pred_actual_df['predictions'] = list(preds)\n",
    "pred_actual_df['actual'] = list(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Metrics: R-Square and Adjusted R-Square</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "result = sm.ols(formula=\"predictions ~actual\", data=pred_actual_df ).fit()\n",
    "# print result.summary()\n",
    "print (\"To compare, the R-Square for the model is: %.4f, and the Adjusted R-Square is: %.4f.\" % (result.rsquared, result.rsquared_adj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_weighted_features = dict(zip( X_train.columns, clf.best_estimator_.coef_))\n",
    "most_important_features = []\n",
    "for k,v in high_weighted_features.items():\n",
    "    if np.absolute(v) >=.01:\n",
    "        most_important_features.append(k)\n",
    "\n",
    "most_important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='7.0'><font color='black'><u>7.0 Model Two: Linear Regression with Deep Neural Network</u></font></a>\n",
    "\n",
    "The next model that will be used to predict wins is a Deep Learning Neural Network.  Deep Learning is an area of machine learning that mimics animal brains by progressively improving on its ability to learn a task through the use of examples. Input is passed into a network of layers called neurons. Each input is assigned which yields an output. \"The DNN finds the correct mathematical manipulation to turn the input into the output, whether it be a linear relationship or a non-linear relationship. The network moves through the layers calculating the probability of each output.\" (https://en.wikipedia.org/wiki/Deep_learning)\n",
    "\n",
    "\"\\[E\\]xposed to enough of the right data, deep learning is able to establish correlations between present events and future events. It can run regression between the past and the future.\"(https://skymind.ai/wiki/neural-network)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=40, activation='relu'))\n",
    "model.add(Dense(units = 32, activation='relu'))\n",
    "model.add(Dense(units = 32, activation='relu'))\n",
    "model.add(Dense(units = 32, activation='relu'))\n",
    "#Output layer\n",
    "model.add(Dense(units = 1))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model.predict(X_test)\n",
    "preds2 = list(preds2[:,0])\n",
    "diff =[]\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    diff.append(preds2[i]- y_test.iloc[i])\n",
    "    print(\"The model predicts %d and the actual number is %d. The difference is %d\" % (preds2[i],y_test.iloc[i], diff[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = [i ** 2 for i in diff]\n",
    "\n",
    "print(\"The Mean Squared Error for this model is %.2f\" % np.mean(mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(preds2, y_test, c=preds2-y_test)\n",
    "plt.xlabel('Model Predictions')\n",
    "plt.ylabel('Actual Wins')\n",
    "plt.title('Model Two Predictions vs. Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "score = r2_score(y_test, preds2)\n",
    "print('The R square score of the Deep Neural Network models is %.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2_actual_df = pd.DataFrame( index=range(0,119))\n",
    "pred2_actual_df['predictions'] = list(preds2)\n",
    "pred2_actual_df['actual'] = list(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "result = sm.ols(formula=\"predictions ~actual\", data=pred2_actual_df ).fit()\n",
    "# print result.summary()\n",
    "print (\"To compare, the R-Square for the model is: %.4f, and the Adjusted R-Square is: %.4f.\" % (result.rsquared, result.rsquared_adj))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Two Summary</b><br/>\n",
    "\n",
    "Model Two confirms the results that were discovered in Model One. The Mean Squared Error on the test data for this model is 37 whereas the MSE for the previous model was 32 which confirms the 21 most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Performance on Unseen Data</b><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import capstoneutils as cp\n",
    "\n",
    "for i in range(0,3):\n",
    "    csvPath = path + \"\\\\FINAL DATASET version 1.0\\\\2018 TEST DATA\\Source\\\\\"\n",
    "    Test_2018_MLB_Stats_df = pd.DataFrame()\n",
    "    print(csvPath)\n",
    "    Test_2018_MLB_Stats_df  = cp.mergeCSVs(csvPath, \"Test_2018_MLB_Stats.csv\", path + r\"\\FINAL DATASET version 1.0\\2018 TEST DATA\\Output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_2018_MLB_Stats_df = Test_2018_MLB_Stats_df.loc[:,~Test_2018_MLB_Stats_df.columns.duplicated()]\n",
    "Team_Wins = (Test_2018_MLB_Stats_df['Team'],Test_2018_MLB_Stats_df['W'])\n",
    "Features_2018_df = Test_2018_MLB_Stats_df.drop(['Team','W'], axis=1)\n",
    "Features_2018_df = Features_2018_df.applymap(cp.remove_percentages)\n",
    "numerical = Features_2018_df .columns.values.tolist()\n",
    "Features_2018_df[numerical] = scaler.fit_transform(Features_2018_df[numerical])\n",
    "# # len(Features_2018_df.columns.values)\n",
    "# X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model One\n",
    "preds_2018 = clf.predict(Features_2018_df)\n",
    "preds_2018 = preds_2018*.83\n",
    "actual_wins = Team_Wins[1]\n",
    "team = Team_Wins[0]\n",
    "for i in range(0, len(actual_wins)):\n",
    "    diff = actual_wins[i] - preds_2018[i]\n",
    "    print(\"The model predicts %d and the actual number is %d. The difference is %d. The team is %s.\" % (preds_2018[i],actual_wins[i], diff, team[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = r2_score( actual_wins, preds_2018)\n",
    "print('The R square score of Model One is %.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = mean_squared_error(actual_wins, clf.predict(Features_2018_df))\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Comparison to the Pythagorean Theorem of Baseball</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Comparison to the Pythagorean\n",
    "model1_predictions = model.predict(X_train.ix[[510]]).tolist()[0][0]\n",
    "model2_predictions = clf.predict(X_train.ix[[510]])[0]\n",
    "print(\"For the team that allowed the least amount of runs, the LASSO model predicted %.0f wins.\" % model1_predictions)\n",
    "print(\"For the team that allowed the least amount of runs, the Deep Neural Networks model predicted %.0f wins.\" % model2_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='8.0'><font color='black'><u>8.0 Hitters Hierarchial Clustering</u></font></a>\n",
    "\n",
    "With the knowledge of the number of features, the project will now turn to cluster analysis of the current players. For this project, we want hierarchial clusters of the players since the goal is to target players whose statistics are a better match for the features that we have discovered in the models. With the knowledge of the number of features, the project will now turn to cluster analysis of the current players. For this project, we want hierarchical clusters of the players since the goal is to target players whose statistics are a better match for the features that we have discovered in the models.  Hierarchical clustering starts out with each observation as its own cluster. It then identifies each cluster that is closest together and merges similar clusters until all clusters are merged into one cluster. \n",
    "\n",
    "\n",
    "For the sake of brevity, the project will focus only on the segments for hitters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.chdir('..')\n",
    "path = os.chdir('..')\n",
    "print(os.getcwd())\n",
    "Player_Hitting_Data = pd.read_csv('2018 Hitting Pitching Stats Players.csv')\n",
    "Player_Fielding_Data = pd.read_csv('2018 Fielding Stats Players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Player_Hit_Field_Data = pd.merge(Player_Hitting_Data, Player_Fielding_Data[['FP','playerid']], how='left', on='playerid')\n",
    "Player_Hit_Field_Data = Player_Hit_Field_Data.drop_duplicates(['playerid'])\n",
    "Player_Hit_Field_Data[Player_Hit_Field_Data.duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Hit_Field_Data[Player_Hit_Field_Data['FP'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Hit_Field_Data = Player_Hit_Field_Data.drop([31,133,213])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the 21 most important features for hitting\n",
    "Player_Hit_Field_Data=Player_Hit_Field_Data.loc[:,['Team','Name','playerid','FP', 'PA', 'ISO', 'BABIP', 'AVG', 'wOBA', 'wRC+', '2B']]\n",
    "\n",
    "Player_Hit_Field_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Hit_Field_Data2 = Player_Hit_Field_Data.drop(['Name','Team'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.scatter_matrix(Player_Hit_Field_Data2.iloc[:,1:8], alpha = 0.3, figsize = (14,8), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Hit_Field_Data2.iloc[:,1:8]= np.log(Player_Hit_Field_Data2.iloc[:,1:8])\n",
    "\n",
    "# Produce a scatter matrix for each pair of newly-transformed features\n",
    "pd.scatter_matrix(Player_Hit_Field_Data2.iloc[:,1:8], alpha = 0.3, figsize = (14,8), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = collections.Counter()\n",
    "cnt = hp.detect_outliers(Player_Hit_Field_Data2.iloc[:,1:8])\n",
    "outliers  = [list(cnt.keys())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt.most_common()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Hit_Field_Data2 = Player_Hit_Field_Data2.drop([221,219])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(Player_Hit_Field_Data2['wOBA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical2 = Player_Hit_Field_Data2.loc[: ,['FP','PA','ISO','BABIP','AVG','wOBA','wRC+','2B']].columns.values.tolist()\n",
    "Player_Hit_Field_Data[numerical2] = scaler.fit_transform(Player_Hit_Field_Data[numerical2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Hitters Dendograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(Player_Hit_Field_Data2.iloc[:,1:8], method='complete'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=2 , affinity='euclidean', linkage='complete')  \n",
    "preds = cluster.fit_predict(Player_Hit_Field_Data2.iloc[:,1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "score = silhouette_score(Player_Hit_Field_Data2,preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Hit_Field_Data2['cluster'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Hit_Field_Data = pd.merge(Player_Hitting_Data, Player_Hit_Field_Data2[['cluster','playerid']], how='left', on='playerid')\n",
    "cluster1 = Player_Hit_Field_Data[Player_Hit_Field_Data['cluster']==1.0]\n",
    "cluster0 = Player_Hit_Field_Data[Player_Hit_Field_Data['cluster']==0.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='black'><b><u>Summary of Hitters Segment Analysis</u></b></font>\n",
    "\n",
    "The segment analysis of the hitters shows that the hitters can be separated largely into two clusters, cluster 0 and cluster 1.  Hitters in cluster 0 are the ones that the team should target in order to meet the features that lead to wins. Earlier, the models showed that the hitting feature with the most weight is weighted on-base average (\"wOBA\").  In the tables below, you see that hitters in cluster 0 have a mean wOBA of 35% while those in cluster 0 have a mean wOBA of 31%.  The other significant offensive statistic that weighs heavily is the weighted Runs Created(\"wRC+\").  Cluster 0 has a mean of 119 wRC+ while cluster 1 has a mean of 95 wRC+.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster 0 statistics\n",
    "cluster0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster 1 statistics\n",
    "cluster1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player to target: <b>Nolan Arenado, 3B Colorado Rockies</b>\n",
    "<br />\n",
    "<img src=\"Arenado.jpg\" align=\"left\"  height=\"100\" width=\"100\" /><br />\n",
    "<br />\n",
    "\n",
    "Perhaps a top player to target is Colorado Rockies 3B, Nolan Arenado who will be free agent in 2020.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='9.0'><font color=black><u>9.0 Final Summary </u></font></a>  \n",
    "\n",
    "Over the last 20 years, teams in MLB have a 14% chance of winning 95 games or more in a season.  This report started off with over 600 features which were reduced to  showed that the key offensive features that the team needs to have are the following:\n",
    "\n",
    "<ol>\n",
    "<li>Field Percentage ('FP'): Fielding percentage: The percentage of times a defensive player properly handles a batted or thrown ball.</li><br />\n",
    "<li>Plate Appearance ('PA'): Number of plate appearances.</li><br />\n",
    "<li>Isolated Power ('ISO'): Average number of extra bases per at bat, calculated several ways such as SLG minus AVG.</li><br />\n",
    "<li>Batted Balls in Play ('BABIP'):The rate at which the batter gets a hit when he puts the ball in play.</li><br />\n",
    "<li>Average('AVG'): Rate of hits per at bat, calculated as H/AB.</li><br />\n",
    "<li>Weighted On Base Average('wOBA'):  Is a statistic, based on linear weights,designed to measure a player's overall offensive contributions per plate appearance. It is formed from taking the observed run values of various offensive events, dividing by a player's plate appearances, and scaling the result to be on the same scale as on-base percentage. </li><br />\n",
    "<li>Weighted Runs Created plus('wRC+'): Quantifies a player’s total offensive value and measure it by runs. It synthesizes all of a players offensive stats and applies a formula to those stats to quantify how many runs a player is worth to his team in comparison to the league average.  Nolan Arenado's wRC+ is 142 which means that he created 42% more runs than the league average.</li><br />\n",
    "<li>Doubles('2B'): Total number of doubles.</li><br />\n",
    "</ol>\n",
    "\n",
    "\n",
    "There are limitations to this analysis.  One, the low number of observations may have an impact the analysis. We cannot determine if there's enough data to build a completely accurate model.  However, there's no way to add more observations.  Going back further than 1998 is also problematic as the number of teams per year may impact the number of wins.  Two, some of the features gathered from fangraphs are not complete for the entirety of the years.  There's a lot of fielding data that was not consistently gathered.   \n",
    "\n",
    "Given these limitations, the most important milestone that this project achieved was to build a systematic approach to understanding how Wins in MLB are created. The approach--gathering the data, cleaning it, pre-processing it, and applying a model to it-- may need to be amended or updated, but this can be followed for future projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='10.0'><font color=black><u>10.0 Project Reflections </u></font></a> \n",
    "\n",
    "<ol>\n",
    "    <li>Baseball is personal passion of mine, and I wanted to do my Capstone project in this domain since MLB is a leader in using statistics to evaluate talent.  Also, there's a wealth of available information.</li><br />\n",
    "    <li>My goal was to make sure that my methodology to this project was sound. I made quite a few decisions that may need to be reversed, but as long as the project methdology is sound, decision changes can be easily incorporated. </li><br />\n",
    "    <li>The project took much long than planned for. Given the deadline, I wasn't able to complete the Pitching segment analysis. Most of the time was taken with the data collection and wrangling.</li><br />\n",
    "    <li>I am open to any suggestions or changes as I consider this project a first draft.</li><br />\n",
    "   </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='11.0'><font color=black><u>11.0 References</u></font></a> \n",
    "<ul>\n",
    "    <li>https://www.fangraphs.com/</li><br />\n",
    "    <li>https://machinelearningmastery.com</li><br />\n",
    "    <li>https://stackoverflow.com/</li><br />\n",
    "    <li>http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py</li><br />\n",
    "    \n",
    "  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
